## ü§ñ Anota√ß√µes Transfer Learning

1. Importando bibliotecas
```
import tensorflow as tf
import tensorflow_datasets as tfds
import matplotlib.pyplot as plt
```

- tensorflow: biblioteca principal usada para construir e treinar redes neurais.
- tensorflow_datasets (tfds): ferramenta da pr√≥pria equipe do TensorFlow que facilita o acesso a bases de dados famosas.
- matplotlib.pyplot: biblioteca usada para visualizar gr√°ficos, como curvas de acur√°cia.

<br/>

2. Carregando o dataset Caltech101
```
(ds_train, ds_test), ds_info = tfds.load(
    'caltech101',
    split=['train[:80%]', 'train[80%:]'],
    shuffle_files=True,
    as_supervised=True,
    with_info=True
)
```

- tfds.load: baixa e prepara o dataset automaticamente.
- 'caltech101': nome do dataset a ser carregado.
- split: separa o conjunto em 80% para treino, 20% para teste.
- shuffle_files=True: embaralha os arquivos para n√£o ter vi√©s na ordem.
- as_supervised=True: retorna tuplas (imagem, r√≥tulo) ao inv√©s de dicion√°rios.
- with_info=True: retorna metadados do dataset (como o nome das classes).

<br/>

3. Verificando os nomes das classes
```
print(ds_info.features['label'].names)
```

- Mostra uma lista com os nomes das 101 classes (ex: 'camera', 'airplanes', etc.).

<br/>

4. Selecionando duas classes espec√≠ficas
```
selected_classes = ['flamingo', 'pigeon']
class_names = ds_info.features['label'].names
selected_ids = [class_names.index(name) for name in selected_classes]
```

- selected_classes: voc√™ define manualmente as duas classes que deseja usar.
- class_names: lista com o nome de todas as classes do dataset.
- selected_ids: obt√©m os √≠ndices num√©ricos correspondentes aos nomes selecionados (necess√°rio para filtrar depois).

<br/>

5. Filtrando apenas essas duas classes
```
def filter_classes(image, label):
    return tf.reduce_any([label == selected_ids[0], label == selected_ids[1]])
```

- Fun√ß√£o que ser√° usada para filtrar apenas imagens cujos r√≥tulos perten√ßam √†s duas classes escolhidas.
- tf.reduce_any(...): retorna True se qualquer condi√ß√£o for verdadeira.

<br/>

6. Reconvertendo r√≥tulos para 0 e 1
```
def reencode_labels(image, label):
    new_label = tf.cast(label == selected_ids[1], tf.int64)
    return image, new_label
```

- Convertemos os r√≥tulos para 0 ou 1 para facilitar o uso de classifica√ß√£o bin√°ria.
- Se o r√≥tulo for igual √† segunda classe (ex: 'motorbikes'), ele vira 1; sen√£o, 0.

<br/>

7. Pr√©-processamento de imagens
```
IMG_SIZE = (160, 160)
BATCH_SIZE = 32

def preprocess(image, label):
    image = tf.image.resize(image, IMG_SIZE) / 255.0
    return image, label
```

- IMG_SIZE: define que todas as imagens ter√£o tamanho 160x160 pixels.
- BATCH_SIZE: n√∫mero de imagens processadas por vez durante o treino.
- preprocess: redimensiona cada imagem e normaliza os pixels (de 0 a 1).

<br/>

8. Aplicando filtros e criando os datasets finais
```
train_ds = ds_train.filter(filter_classes).map(reencode_labels).map(preprocess).batch(BATCH_SIZE).prefetch(1)
test_ds = ds_test.filter(filter_classes).map(reencode_labels).map(preprocess).batch(BATCH_SIZE).prefetch(1)
```

- .filter(...): aplica a fun√ß√£o de filtro para manter s√≥ as duas classes.
- .map(...): aplica a convers√£o de r√≥tulos e depois o pr√©-processamento.
- .batch(BATCH_SIZE): agrupa imagens em lotes de 32.
- .prefetch(1): melhora o desempenho carregando os dados enquanto o modelo treina.

<br/>

9. Carregando o modelo pr√©-treinado MobileNetV2
```
base_model = tf.keras.applications.MobileNetV2(
    input_shape=IMG_SIZE + (3,),
    include_top=False,
    weights='imagenet'
)
base_model.trainable = False
```

- MobileNetV2: rede treinada com milh√µes de imagens (ImageNet).
- input_shape: precisa combinar com o tamanho das nossas imagens (160x160x3).
- include_top=False: remove a ‚Äúcabe√ßa‚Äù original do modelo (classificador original).
- weights='imagenet': carrega os pesos j√° treinados.
- trainable=False: congela os pesos para usar como extrator de caracter√≠sticas fixo.

<br/>

10. Adicionando novas camadas para nosso problema
```
model = tf.keras.Sequential([
    base_model,
    tf.keras.layers.GlobalAveragePooling2D(),
    tf.keras.layers.Dense(1, activation='sigmoid')
])
```

- Sequential: cria uma pilha de camadas.
- GlobalAveragePooling2D: resume cada mapa de ativa√ß√£o com uma m√©dia (reduz par√¢metros).
- Dense(1, activation='sigmoid'): camada final com 1 sa√≠da para classifica√ß√£o bin√°ria.

<br/>

11. Compilando o modelo
```
model.compile(optimizer='adam',
              loss='binary_crossentropy',
              metrics=['accuracy'])
```

- optimizer='adam': algoritmo eficiente para ajuste dos pesos.
- loss='binary_crossentropy': fun√ß√£o de perda usada em classifica√ß√µes bin√°rias.
- metrics=['accuracy']: acompanha a acur√°cia durante o treinamento.

<br/>

12. Treinando o modelo
```
history = model.fit(
    train_ds,
    validation_data=test_ds,
    epochs=5
)
```

- model.fit(...): treina o modelo.
- epochs=5: faz 5 passagens completas pelos dados.
- validation_data: valida√ß√£o com dados que o modelo nunca viu.

<br/>

13. Visualizando a acur√°cia
```
acc = history.history['accuracy']
val_acc = history.history['val_accuracy']

plt.plot(acc, label='Treinamento')
plt.plot(val_acc, label='Valida√ß√£o')
plt.legend()
plt.title("Acur√°cia por √âpoca")
plt.show()
```

- history.history: cont√©m os registros da acur√°cia a cada √©poca.
- plt.plot: desenha os gr√°ficos para comparar treino vs. valida√ß√£o.
- Isso ajuda a ver se o modelo est√° aprendendo ou sofrendo overfitting.

---
Caltech 101 - Dataset
1. F.-F. Li, M. Andreeto, M. Ranzato, P. Perona, Caltech 101 (2022)p. , doi:10.22002/D1.20086.
